---
title: "Welcome to Polos"
description: "Durable execution platform for AI agents"
---

# Introduction

Polos is a **durable execution platform** for AI agents.
It provides the stateful infrastructure required to run long-running, autonomous agents reliably at scale -
including a built-in event system for agent coordination, so you don't need to bolt on Kafka or RabbitMQ.

Write it all in plain Python or TypeScript.
No DAGs to define, no graph syntax to learn. Use loops, conditionals, and function calls
naturally while Polos handles durability, reliability and scaling automatically.

<CodeGroup>

```python Python
from polos import Agent, workflow, WorkflowContext

order_validation_agent = Agent(
    provider="openai",
    model="gpt-4o",
    tools=[check_inventory, calculate_shipping]
)

@workflow(trigger_on_event="order/new")
async def process_order(ctx: WorkflowContext, order: ProcessOrderInput):
    # Agent validates order and checks inventory
    validation = await ctx.step.agent_invoke_and_wait(
        "validate_order",
        order_validation_agent.with_input(f"Validate this order: {order}")
    )

    if not validation.result.valid:
        return ProcessOrderOutput(
            status="invalid",
            reason=validation.result.reason
        )

    # High-value orders need approval
    if order.amount > 1000:
        # Suspend execution until the order is approved or rejected
        resume_data = await ctx.step.suspend(
            "approval",
            data={
                "id": order.id,
                "amount": order.amount,
                "items": order.items,
                "user": order.user
            }
        )
        decision = resume_data.get("data", {})
        if not decision.get("approved"):
            return ProcessOrderOutput(
                status="rejected",
                reason=decision.get("reason")
            )

    # Charge customer (exactly-once guarantee)
    payment = await ctx.step.run("charge", charge_stripe, order)

    # Wait for warehouse pickup (could be hours or days)
    await ctx.step.wait_for_event(
        "wait_pickup",
        topic=f"warehouse.pickup/{order.id}"
    )

    # Send shipping notification
    await ctx.step.run("notify", send_shipping_email, order)

    return ProcessOrderOutput(status="completed", payment_id=payment.id)
```

```typescript TypeScript
import { defineAgent, defineWorkflow } from '@polos/sdk';
import { openai } from '@ai-sdk/openai';

const orderValidationAgent = defineAgent({
  id: 'order_validation_agent',
  model: openai('gpt-4o'),
  tools: [checkInventory, calculateShipping],
});

const processOrder = defineWorkflow<ProcessOrderInput, unknown, ProcessOrderOutput>(
  { id: 'process_order', triggerOnEvent: 'order/new' },
  async (ctx, order) => {
    // Agent validates order and checks inventory
    const validation = await ctx.step.agentInvokeAndWait(
      'validate_order',
      orderValidationAgent.withInput(`Validate this order: ${JSON.stringify(order)}`),
    );

    if (!validation.result.valid) {
      return { status: 'invalid', reason: validation.result.reason };
    }

    // High-value orders need approval
    if (order.amount > 1000) {
      // Suspend execution until the order is approved or rejected
      const resumeData = await ctx.step.suspend('approval', {
        data: {
          id: order.id,
          amount: order.amount,
          items: order.items,
          user: order.user,
        },
      });
      const decision = (resumeData?.['data'] as Record<string, unknown>) ?? {};
      if (!decision['approved']) {
        return { status: 'rejected', reason: decision['reason'] as string };
      }
    }

    // Charge customer (exactly-once guarantee)
    const payment = await ctx.step.run('charge', () => chargeStripe(order));

    // Wait for warehouse pickup (could be hours or days)
    await ctx.step.waitForEvent('wait_pickup', {
      topic: `warehouse.pickup/${order.id}`,
    });

    // Send shipping notification
    await ctx.step.run('notify', () => sendShippingEmail(order));

    return { status: 'completed', paymentId: payment.id };
  },
);
```

</CodeGroup>

This workflow survives crashes, resumes mid-execution, and pauses for approval - all with zero manual checkpointing, retry logic or queue management.

## The Problem

Most AI agents work in demos but break in production. They're long-running distributed systems, yet we run them on infrastructure built for stateless APIs.

What breaks:

- Server restarts lose all progress
- Failed API calls restart from scratch, wasting tokens
- Difficult to pause for human approval
- Multi-agent systems can't share context reliably
- One workflow can exhaust your entire OpenAI quota

## See It in Action

Imagine a workflow that charges a customer, then pauses for a human fraud review. In most frameworks, a server restart during that 24-hour wait would lose the state - or worse, re-run the charge on reboot. Polos guarantees exactly-once durable execution.

<video src="/videos/polos-demo.mp4" controls width="100%"></video>

**Timeline of what's happening:**

1. `charge_stripe` runs ‚Üí Polos checkpoints the execution result
2. Workflow suspends for fraud review ‚Üí Worker resources freed
3. Worker 1 crashes during the wait
4. Fraud team approves ‚Üí Signal sent to orchestrator
5. Worker 2 resumes on a different machine ‚Üí Stripe is **not** called again, result replayed from the log guaranteeing exactly-once execution
6. Confirmation email sent ‚Üí workflow completes

Polos handles failures, rescheduling, and checkpointing. You just focus on business logic.

## Logic Belongs in Code, Not Configs

**With Polos:**

<CodeGroup>

```python Python
@workflow
async def process_order(ctx: WorkflowContext, order: ProcessOrderInput):
    # Just write Python
    if order.amount > 1000:
        resume_data = await ctx.step.suspend("approval", data=order.model_dump())
        decision = resume_data.get("data", {})
        if not decision.get("ok"):
            return {"status": "rejected"}

    await ctx.step.run("charge", charge_stripe, order)
    await ctx.step.run("notify", send_email, order)
```

```typescript TypeScript
const processOrder = defineWorkflow<ProcessOrderInput, unknown, Record<string, unknown>>(
  { id: 'process_order' },
  async (ctx, order) => {
    // Just write TypeScript
    if (order.amount > 1000) {
      const resumeData = await ctx.step.suspend('approval', { data: order });
      const decision = (resumeData?.['data'] as Record<string, unknown>) ?? {};
      if (!decision['ok']) {
        return { status: 'rejected' };
      }
    }

    await ctx.step.run('charge', () => chargeStripe(order));
    await ctx.step.run('notify', () => sendEmail(order));
  },
);
```

</CodeGroup>

**Other platforms:**

```python
# Define rigid DAGs upfront
dag = DAG(
    nodes=[
        Node("check_amount", CheckAmount),
        Node("approval", HumanApproval),
        Node("charge", ChargeStripe),
        Node("notify", SendEmail),
    ],
    edges=[
        ("check_amount", "approval", condition="amount > 1000"),
        ("check_amount", "charge", condition="amount <= 1000"),
        ("approval", "charge", condition="approved"),
        ("charge", "notify"),
    ]
)
```

With Polos, there are no DAGs to define, no graph syntax to learn. Use loops, conditionals, and function calls naturally while Polos handles durability automatically.

## Why Polos?

üß† **Durable State**: Your agent survives crashes with call stack and local variables intact. Step 18 of 20 fails? Resume from step 18. No wasted LLM calls, no manual checkpointing or state-machine hacks required.

**üö¶ Global Concurrency**: System-wide rate limiting with queues and concurrency keys. Prevent one rogue agent from exhausting your entire OpenAI quota. Only active executions count toward limits - queued runs wait their turn without consuming resources.

**ü§ù Human-in-the-Loop**: Native support for pausing execution. Wait hours or days for user approval and resume with full context. In serverless environments, paused agents consume zero compute - you only pay when they're actively running.

**üì° Agent Handoffs**: Transactional memory for multi-agent systems. Pass reasoning history between specialized agents without context drift. Shared working memory enables true agent collaboration.

**üîç Decision-Level Observability**: Trace the reasoning behind every tool call, not just raw logs. See why your agent chose Tool B over Tool A. Debug deterministic failures in stochastic systems.

**‚ö° Production Ready**: Automatic retries, exactly-once execution guarantees, OpenTelemetry tracing built-in. Scales to millions of concurrent workflows.

## What Can You Build?

üî¨ **Research assistants**: Multi-hour workflows that search, analyze, and synthesize information across dozens of sources

üí∞ **Financial operations**: Approval workflows that pause for human review, then execute Stripe charges with exactly-once guarantees

ü§ñ **Multi-agent systems**: Specialized agents (researcher, writer, editor) that coordinate via shared memory to complete complex tasks

‚öôÔ∏è **Background automation**: Long-running jobs that survive deploys and resume seamlessly (data migrations, batch processing, ETL pipelines)

## How It Works

Polos captures the result of every side effect - tool calls, API responses, time delays as a durable log.
If your process dies, Polos replays the workflow from the log, returning previously-recorded results instead of re-executing them.
Your agent's exact local variables and call stack are restored in milliseconds.
Completed steps are never re-executed - so you're never paying for the same LLM call twice.

<Note>
Polos is open source! [‚≠ê Star us on GitHub](https://github.com/polos-dev/polos) if you find it useful, and [join our Discord](https://discord.gg/ZAxHKMPwFG) to connect with the community.
</Note>

## Next Steps

<CardGroup cols={3}>
  <Card
    title="Quickstart"
    icon="rocket"
    href="/quickstart"
  >
    Deploy your first durable agent in 5 minutes
  </Card>
  <Card
    title="Core Concepts"
    icon="lightbulb"
    href="/fundamentals/overview"
  >
    Learn how Polos handles state and durability
  </Card>
  <Card
    title="Examples"
    icon="book-open"
    href="/guides/cookbook-examples"
  >
    See how to build HITL agents and multi-agent systems
  </Card>
</CardGroup>
